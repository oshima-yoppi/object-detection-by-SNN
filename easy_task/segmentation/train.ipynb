{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "from snntorch import utils\n",
    "from snntorch import functional as SF\n",
    "from snntorch import surrogate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from tonic import DiskCachedDataset\n",
    "import tonic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from custom_data import LoadDataset\n",
    "import custom_data\n",
    "from model import model, compute_loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_pass(net, data):\n",
    "    spk_rec = []\n",
    "    utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "    for step in range(data.size(0)):  # data.size(0) = number of time steps\n",
    "        spk_out, mem_out = net(data[step])\n",
    "        spk_rec.append(spk_out)\n",
    "\n",
    "    return torch.stack(spk_rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "num_inputs = 28*28\n",
    "num_hidden = 1000\n",
    "num_outputs = 10\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# Temporal Dynamics\n",
    "num_steps = 10\n",
    "beta = 0.95\n",
    "dataset_path = \"dataset/\"\n",
    "batch_size = 16\n",
    "\n",
    "train_dataset = LoadDataset(dir = dataset_path, train=True)\n",
    "test_dataset = LoadDataset(dir = dataset_path,  train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=custom_data.custom_collate, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=custom_data.custom_collate, shuffle=False,)\n",
    "\n",
    "\n",
    "spike_grad = surrogate.atan()\n",
    "net = model.cnn(beta=beta, spike_grad=spike_grad).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "# loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
    "\n",
    "num_epochs = 100\n",
    "num_iters = 50\n",
    "pixel = 64\n",
    "correct_rate = 0.8\n",
    "loss_hist = []\n",
    "acc_hist = defaultdict(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for i, (data, label) in enumerate(iter(train_loader)):\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "        batch = len(data[0])\n",
    "        data = data.reshape(num_steps, batch, 1, pixel, pixel)\n",
    "\n",
    "        net.train()\n",
    "        spk_rec = forward_pass(net, data)# time batch neuron ???\n",
    "        loss_val = compute_loss.spike_mse_loss(spk_rec, label, rate=correct_rate)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # print(f\"Epoch {epoch}, Iteration {i} /nTrain Loss: {loss_val.item():.2f}\")\n",
    "\n",
    "        acc = compute_loss.culc_iou(spk_rec, label)\n",
    "        acc_hist['train'].append(acc)\n",
    "        # print(f\"Accuracy: {acc * 100:.2f}%/n\")\n",
    "        # break\n",
    "    tqdm.write(f'{acc=}')\n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for i, (data, label) in enumerate(iter(test_loader)):\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            batch = len(data[0])\n",
    "            data = data.reshape(num_steps, batch, 1, pixel, pixel)\n",
    "            spk_rec = forward_pass(net, data)\n",
    "            loss_val = compute_loss.spike_mse_loss(spk_rec, label)\n",
    "            acc = compute_loss.culc_iou(spk_rec, label)\n",
    "            acc_hist['test'].append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Loss\n",
    "print(acc_hist)\n",
    "fig = plt.figure(facecolor=\"w\")\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax1.plot(acc_hist['train'], label=\"train\")\n",
    "ax1.set_title(\"Train Set Accuracy\")\n",
    "ax1.set_xlabel(\"Iteration\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax2.plot(acc_hist['test'], label='test')\n",
    "ax2.set_title(\"Train Set Accuracy\")\n",
    "ax2.set_xlabel(\"epoch\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## save model\n",
    "enddir = \"models/model1.pth\"\n",
    "torch.save(net.state_dict(), enddir)\n",
    "print(\"success model saving\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac0c0a8d7fd91358fa9d1d592be102326233f2c9d5171857c508a7a1b2392c47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
