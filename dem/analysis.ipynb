{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "from snntorch import utils\n",
    "from snntorch import functional as SF\n",
    "from snntorch import surrogate\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "# from collections import defaultdict\n",
    "\n",
    "from module.custom_data import LoadDataset\n",
    "from module import custom_data, network, compute_loss, view\n",
    "from module.const import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# いろいろ定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = LoadDataset(processed_event_dataset_path=PROCESSED_EVENT_DATASET_PATH, raw_event_dir=RAW_EVENT_PATH, accumulate_time=ACCUMULATE_EVENT_MICROTIME , input_height=INPUT_HEIGHT, input_width=INPUT_WIDTH,train=True)\n",
    "test_dataset = LoadDataset(processed_event_dataset_path=PROCESSED_EVENT_DATASET_PATH, raw_event_dir=RAW_EVENT_PATH, accumulate_time=ACCUMULATE_EVENT_MICROTIME , input_height=INPUT_HEIGHT, input_width=INPUT_WIDTH, train=False)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TEST, collate_fn=custom_data.custom_collate, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, collate_fn=custom_data.custom_collate, shuffle=False,)\n",
    "\n",
    "\n",
    "\n",
    "net = NET\n",
    "net.load_state_dict(torch.load(MODEL_PATH))\n",
    "# corract_rate  = 0.5\n",
    "events, _ = train_dataset[0]\n",
    "num_steps = events.shape[0]\n",
    "\n",
    "ious = []\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出力結果の解析\n",
    "危険とみなすスパイク数の閾値を変化させたときの、出力画像やiouを算出する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [02:58<00:00,  3.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# def get_first_frame(video_path):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     _, frame = cap.read()\n",
    "#     return frame\n",
    "\n",
    "# def get_first_events(events):\n",
    "#     events = events.to('cpu')\n",
    "#     if BOOL_DISTINGUISH_EVENT:\n",
    "#         first_events = np.zeros((INPUT_HEIGHT, INPUT_WIDTH, 3)) # bgr\n",
    "#         first_events[:,:,0] = events[0,0,0] * 255# r \n",
    "#         first_events[:,:,1] = events[0,0,1] * 255\n",
    "#         return first_events\n",
    "def save_img(number, events, pred_pro, label, iou, pdf_output):\n",
    "    # label = label.reshape((pixel, pixel)).to('cpu')\n",
    "    # print(pred_pro.shape)\n",
    "    number_str = str(number).zfill(5)\n",
    "    num_steps = len(pred_pro)\n",
    "    nrows = 2\n",
    "    ncols = 5\n",
    "    fig = plt.figure()\n",
    "    # ax1 = fig.add_subplot(231)\n",
    "    ax2 = fig.add_subplot(232)\n",
    "    ax3 = fig.add_subplot(233)\n",
    "    ax4 = fig.add_subplot(234)\n",
    "    ax5 = fig.add_subplot(235)\n",
    "    ax6 = fig.add_subplot(236)\n",
    "\n",
    "\n",
    "    # dem_filename = f'dem_{str(number).npy}'\n",
    "    # dem_path = os.path.join(DEM_NP_PATH, dem_filename)\n",
    "    # dem = np.load(dem_path)\n",
    "    # ax1.imshow(dem)\n",
    "\n",
    "    video_filename = f'{number_str}.avi'\n",
    "    video_path = os.path.join(VIDEO_PATH, video_filename)\n",
    "    first_frame = view.get_first_frame(video_path) \n",
    "    ax2.set_title('Camera_view')\n",
    "    ax2.imshow(first_frame)\n",
    "\n",
    "    first_events = view.get_first_events(events) \n",
    "    ax3.set_title('EVS view')\n",
    "    ax3.imshow(first_events)\n",
    "\n",
    "    label_ =label.reshape((INPUT_HEIGHT, INPUT_WIDTH)).to('cpu')\n",
    "    ax4.imshow(label_)\n",
    "    ax4.set_title('label')\n",
    "\n",
    "    pred_pro_ = pred_pro[:, 1, :, :]\n",
    "    pred_pro_ = pred_pro_.reshape((INPUT_HEIGHT, INPUT_WIDTH)).to('cpu').detach().numpy().copy()\n",
    "    ax5.imshow(pred_pro_)\n",
    "    ax5.set_title('Estimated Probability')\n",
    "\n",
    "    ax6.imshow(np.where(pred_pro_>=CORRECT_RATE, 1, 0))\n",
    "    ax6.set_title('Safe or Dangerous')\n",
    "\n",
    "    fig.suptitle(f\"No.{number} IoU:{round(iou, 3)}  ModelName:{MODEL_NAME}\")\n",
    "    plt.tight_layout()\n",
    "    # plt.show()\n",
    "    # exit()\n",
    "    img_path = os.path.join(RESULT_PATH, f'{str(i).zfill(5)}.png')\n",
    "    fig.savefig(img_path)\n",
    "    if pdf_output:\n",
    "        img_path = os.path.join(RESULT_PATH, f'{str(i).zfill(5)}.pdf')\n",
    "        fig.savefig(img_path)\n",
    "    plt.close()\n",
    "\n",
    "hist = defaultdict(list)\n",
    "if os.path.exists(RESULT_PATH):\n",
    "        shutil.rmtree(RESULT_PATH)\n",
    "os.makedirs(RESULT_PATH)\n",
    "spikes_lst = []\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    for i, (events, label) in enumerate(tqdm(iter(test_loader))):\n",
    "        events = events.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        batch = len(events[0])\n",
    "        # print(events.shape)# TBCHW\n",
    "        # events = events.reshape(num_steps, batch, INPUT_CHANNEL, INPUT_HEIGHT, INPUT_WIDTH)\n",
    "        pred_pro = net(events, FINISH_TIME)\n",
    "        \n",
    "        iou = compute_loss.culc_iou(pred_pro, label, CORRECT_RATE)\n",
    "        ious.append(iou)\n",
    "        # pred_pro = compute_loss.show_pred(pred_pro, correct_rate)\n",
    "        spikes_lst.append(net.spike_count)  \n",
    "      \n",
    "        save_img(i, events, pred_pro, label,  iou, pdf_output=False)\n",
    "        # break\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 閾値毎のIOUの平均算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullyConv2_new_100000_(130,173)_th-0.15_para-True_TimeChange-False_FinishTime-5_Reset-subtract 0.7671972944835822\n"
     ]
    }
   ],
   "source": [
    "iou_mean = sum(ious)/len(ious)\n",
    "print(MODEL_NAME, iou_mean)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ここからエネルギー計算\n",
    "## 全ての発火数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_spikes=tensor(884616.6875, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n_spikes = sum(spikes_lst)/len(spikes_lst)\n",
    "print(f'{n_spikes=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.9616e-07, device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jules_per_spike = 0.9e-12 #J\n",
    "# jules_per_spike = 0.45e-9 #J hide\n",
    "n_spikes*jules_per_spike"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スパイクの更新エネルギーを計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0022799214"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = 0\n",
    "for p in net.parameters():\n",
    "    if p.requires_grad:\n",
    "        params += p.numel()\n",
    "        \n",
    "print(params)  # 121898\n",
    "jules_ = params*FINISH_TIME*2.19e-9\n",
    "jules_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 発火率を求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2486, device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spike_rate = n_spikes/params\n",
    "spike_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac0c0a8d7fd91358fa9d1d592be102326233f2c9d5171857c508a7a1b2392c47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
